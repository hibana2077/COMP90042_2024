{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact checking system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1208827, dict)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_set = json.load(open('./data/evidence.json'))\n",
    "len(evidence_set), type(evidence_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evidence-0', 'evidence-1', 'evidence-2', 'evidence-3', 'evidence-4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(evidence_set.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Bennet Lawes, English entrepreneur and agricultural scientist'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_set['evidence-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, dict)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = json.load(open('./data/train-claims.json'))\n",
    "len(train_set), type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claim-1937', 'claim-126', 'claim-2510', 'claim-2021', 'claim-2449']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_set.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim_text': 'Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life.',\n",
       " 'claim_label': 'DISPUTED',\n",
       " 'evidences': ['evidence-442946', 'evidence-1194317', 'evidence-12171']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['claim-1937']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- claim_text: the text of the claim\n",
    "- claim_label: {SUPPORTS, REFUTES, NOT ENOUGH INFO, DISPUTED}\n",
    "- evidence: a list of evidence documents and the sentence index in those documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "1. Using vectorization to find the similarity between the claim and the evidence.\n",
    "2. Using Language Model to classify the claim_label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sec513/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train a model that can shows relevant evidence for a given claim\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/MobileLLM-125M\", use_fast=False)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of evidence: 479\n",
      "Index of Max length of evidence: 358371\n",
      "Total number of evidence: 1208827\n",
      "Total number of claims: 1228\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max length of evidence: {max([len(evidence_set[e].split()) for e in evidence_set])}\")\n",
    "print(f\"Index of Max length of evidence: {np.argmax([len(evidence_set[e].split()) for e in evidence_set])}\")\n",
    "print(f\"Total number of evidence: {len(evidence_set)}\")\n",
    "print(f\"Total number of claims: {len(train_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Input: claim, evidence Output: 1 if evidence is relevant to claim, 0 otherwise\n",
    "\n",
    "class EvidenceDataset(Dataset):\n",
    "    def __init__(self, claim_set: Dict[str, str], evidence_set: Dict[str, str], tokenizer, max_length=768):\n",
    "        self.claim_set = claim_set\n",
    "        self.evidence_set = evidence_set\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.claim_keys = list(claim_set.keys())\n",
    "        self.evidence_keys = list(evidence_set.keys())\n",
    "        self.data = []\n",
    "        self.positive_samples = 0\n",
    "        self.negatives_samples = 0\n",
    "        for claim_key in tqdm.tqdm(self.claim_keys):\n",
    "            claim = claim_set[claim_key]\n",
    "            for evidence_key in self.evidence_keys:\n",
    "                evidence = evidence_set[evidence_key]\n",
    "                # self.data.append((claim['claim_text'], evidence, 1 if evidence_key in claim['evidences'] else 0))\n",
    "                if evidence_key in claim['evidences']:\n",
    "                    self.data.append((claim['claim_text'], evidence, 1))\n",
    "                    self.positive_samples += 1\n",
    "                elif self.negatives_samples < self.positive_samples:\n",
    "                    self.data.append((claim['claim_text'], evidence, 0))\n",
    "                    self.negatives_samples += 1\n",
    "        random.shuffle(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        claim, evidence, label = self.data[idx]\n",
    "        inputs_claim = self.tokenizer(claim, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        inputs_evi = self.tokenizer(evidence, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        inputs = (inputs_claim['input_ids'], inputs_evi['input_ids'])\n",
    "        return inputs, label\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        inputs, labels = zip(*batch)\n",
    "        input_ids_claim, input_ids_evi = zip(*inputs)\n",
    "        input_ids_claim = torch.stack(input_ids_claim)\n",
    "        input_ids_evi = torch.stack(input_ids_evi)\n",
    "        labels = torch.tensor(labels)\n",
    "        return (input_ids_claim, input_ids_evi), labels\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return [b[1] for b in self.data]\n",
    "    \n",
    "    def get_predictions(self, outputs):\n",
    "        return outputs.logits.sigmoid().round().squeeze().tolist()\n",
    "    \n",
    "    def get_predictions_and_labels(self, outputs):\n",
    "        return self.get_predictions(outputs), self.get_labels()\n",
    "    \n",
    "# get one and show shape\n",
    "\n",
    "if os.path.exists('./data/dataset.pkl'):\n",
    "    dataset = pickle.load(open('./data/dataset.pkl', 'rb'))\n",
    "else:\n",
    "    dataset = EvidenceDataset(train_set, evidence_set, tokenizer)\n",
    "    # save dataset\n",
    "    pickle.dump(dataset, open('./data/dataset.pkl', 'wb'))\n",
    "inputs, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 4122 Negative samples: 4122\n"
     ]
    }
   ],
   "source": [
    "print(f\"Positive samples: {dataset.positive_samples} Negative samples: {dataset.negatives_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]), torch.Size([1, 512]), 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape, inputs[1].shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RelevantModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.claim_encoder = torch.nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.evidence_encoder = torch.nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.linear = torch.nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, claim_input_ids, evidence_input_ids):\n",
    "        claim_output = self.claim_encoder(claim_input_ids)\n",
    "        evidence_output = self.evidence_encoder(evidence_input_ids)\n",
    "        out_score = self.linear(torch.cat((claim_output, evidence_output), dim=1))\n",
    "        return out_score\n",
    "    \n",
    "# test model\n",
    "\n",
    "model = RelevantModel()\n",
    "outputs = model(inputs[0].float(), inputs[1].float())\n",
    "outputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - batch 17/17 - loss: 0.65759\r"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RelevantModel()\n",
    "model.to(DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    cnt = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.to(DEVICE)\n",
    "        inputs_claim, inputs_evi = inputs\n",
    "        inputs_claim = inputs_claim.to(DEVICE)\n",
    "        inputs_evi = inputs_evi.to(DEVICE)\n",
    "        inputs_claim = inputs_claim.squeeze().float()\n",
    "        inputs_evi = inputs_evi.squeeze().float()\n",
    "        outputs = model(inputs_claim, inputs_evi)\n",
    "        avg_loss += loss_fn(outputs.squeeze(), labels.float()).item()\n",
    "        loss = loss_fn(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cnt += 1\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - batch {cnt}/{len(train_loader)} - loss: {avg_loss/cnt:.5f}\", end=\"\\r\")\n",
    "    losses.append(avg_loss/cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1998 2124]\n",
      " [ 995 3127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.48      0.56      4122\n",
      "           1       0.60      0.76      0.67      4122\n",
      "\n",
      "    accuracy                           0.62      8244\n",
      "   macro avg       0.63      0.62      0.61      8244\n",
      "weighted avg       0.63      0.62      0.61      8244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for batch in train_loader:\n",
    "    inputs, label = batch\n",
    "    inputs_claim, inputs_evi = inputs\n",
    "    inputs_claim = inputs_claim.to(DEVICE).squeeze().float()\n",
    "    inputs_evi = inputs_evi.to(DEVICE).squeeze().float()\n",
    "    outputs = model(inputs_claim, inputs_evi)\n",
    "    preds = (outputs.sigmoid().round().squeeze().tolist())\n",
    "    predictions += preds\n",
    "    labels += label\n",
    "\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "print(cm)\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Language Model\n",
    "\n",
    "- Using Mamba to classify the claim_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class SwiGLU(nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         x, gate = x.chunk(2, dim=-1)\n",
    "#         return F.silu(gate) * x\n",
    "\n",
    "# class ClassifierModelSmall(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.core = nn.Sequential(\n",
    "#             nn.Linear(768, 4096),\n",
    "#             nn.Dropout(0.1),\n",
    "#             SwiGLU(),\n",
    "#             nn.Linear(2048, 768),\n",
    "#             nn.LayerNorm(768)\n",
    "#         )\n",
    "#         self.linear = torch.nn.Linear(768, 4)\n",
    "    \n",
    "#     def forward(self, input_ids):\n",
    "#         input_ids = input_ids.float()\n",
    "#         outputs = self.core(input_ids)\n",
    "#         return self.linear(outputs)\n",
    "    \n",
    "# test_tensor = torch.randint(0, 48051, (2, 768))\n",
    "# model = ClassifierModelSmall()\n",
    "# outputs = model(test_tensor)\n",
    "# total_params = sum(p.numel() for p in model.parameters())/1e6\n",
    "# outputs.shape, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), 124.442884)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define small bert model\n",
    "class SmallBertModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = GPT2Model.from_pretrained('gpt2')\n",
    "        self.linear = torch.nn.Linear(768, 4)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        outputs = self.bert(input_ids)\n",
    "        return self.linear(outputs.last_hidden_state[:, 0, :])\n",
    "    \n",
    "test_tensor = torch.randint(0, 48051, (2, 768))\n",
    "model = SmallBertModel()\n",
    "outputs = model(test_tensor)\n",
    "total_params = sum(p.numel() for p in model.parameters())/1e6\n",
    "outputs.shape, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [00:00<00:00, 99371.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# get one and show shape\u001b[39;00m\n\u001b[1;32m     58\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ClassifierDataset(train_set, evidence_set, tokenizer)\n\u001b[0;32m---> 59\u001b[0m inputs, label \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupports: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mlabels_count[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUPPORTS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Refutes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mlabels_count[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREFUTES\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Not enough info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mlabels_count[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOT_ENOUGH_INFO\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Disputed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mlabels_count[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDISPUTED\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, label\n",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m, in \u001b[0;36mClassifierDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     30\u001b[0m     claim, evidence, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 31\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclaim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     temp_max_token \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m temp_max_token \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_token:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3055\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3055\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3163\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   3143\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3144\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3160\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3161\u001b[0m     )\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3166\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3181\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3228\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;124;03m        method).\u001b[39;00m\n\u001b[1;32m   3225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m-> 3228\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3234\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[1;32m   3238\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3239\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3256\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3257\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2959\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[1;32m   2958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 2959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2963\u001b[0m     )\n\u001b[1;32m   2965\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n\u001b[1;32m   2966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2967\u001b[0m     truncation_strategy \u001b[38;5;241m!=\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE\n\u001b[1;32m   2968\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (max_length \u001b[38;5;241m%\u001b[39m pad_to_multiple_of \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2972\u001b[0m ):\n",
      "\u001b[0;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
     ]
    }
   ],
   "source": [
    "# make dataset (input: claim+evidence, output: label)\n",
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, claim_set: Dict[str, str], evidence_set: Dict[str, str], tokenizer, max_length=768):\n",
    "        self.claim_set = claim_set\n",
    "        self.evidence_set = evidence_set\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.claim_keys = list(claim_set.keys())\n",
    "        self.evidence_keys = list(evidence_set.keys())\n",
    "        self.data = []\n",
    "        self.max_token = 0\n",
    "        # - claim_label: {SUPPORTS, REFUTES, NOT ENOUGH INFO, DISPUTED}\n",
    "        self.labels_map = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2, \"DISPUTED\": 3}\n",
    "        self.labels_count = {\"SUPPORTS\": 0, \"REFUTES\": 0, \"NOT_ENOUGH_INFO\": 0, \"DISPUTED\": 0}\n",
    "        for claim_key in tqdm.tqdm(self.claim_keys):\n",
    "            claim = claim_set[claim_key]\n",
    "            evidence_list = claim['evidences']\n",
    "            temp_evidence = []\n",
    "            for evidence_key in evidence_list:\n",
    "                temp_evidence.append(evidence_set[evidence_key])\n",
    "            temp_evidence = \" \".join(temp_evidence)\n",
    "            self.data.append((claim['claim_text'], temp_evidence, self.labels_map[claim['claim_label']]))\n",
    "            self.labels_count[claim['claim_label']] += 1\n",
    "        random.shuffle(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        claim, evidence, label = self.data[idx]\n",
    "        inputs = self.tokenizer(claim, evidence, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        temp_max_token = torch.max(inputs['input_ids'])\n",
    "        if temp_max_token > self.max_token:\n",
    "            self.max_token = temp_max_token\n",
    "        # label to one-hot\n",
    "        label = torch.nn.functional.one_hot(torch.tensor(label), num_classes=4)\n",
    "        # convert to np array\n",
    "        label = label.numpy()\n",
    "        return inputs, label\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        inputs, labels = zip(*batch)\n",
    "        input_ids = [i['input_ids'] for i in inputs]\n",
    "        input_ids = torch.stack(input_ids)\n",
    "        labels = torch.tensor(labels)\n",
    "        return input_ids, labels\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return [b[1] for b in self.data]\n",
    "    \n",
    "    def get_predictions(self, outputs):\n",
    "        return outputs.logits.argmax(dim=1).squeeze().tolist()\n",
    "    \n",
    "    def get_predictions_and_labels(self, outputs):\n",
    "        return self.get_predictions(outputs), self.get_labels()\n",
    "    \n",
    "# get one and show shape\n",
    "dataset = ClassifierDataset(train_set, evidence_set, tokenizer)\n",
    "inputs, label = dataset[0]\n",
    "print(f\"Supports: {dataset.labels_count['SUPPORTS']} Refutes: {dataset.labels_count['REFUTES']} Not enough info: {dataset.labels_count['NOT_ENOUGH_INFO']} Disputed: {dataset.labels_count['DISPUTED']}\")\n",
    "inputs['input_ids'].shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(46023), 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.max_token , dataset.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_290706/2645981716.py:45: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  labels = torch.tensor(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - batch 1/614 - loss: 1.49975                                              \r"
     ]
    }
   ],
   "source": [
    "# clearup cuda memory\n",
    "torch.cuda.empty_cache()\n",
    "# train model\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SmallBertModel()\n",
    "model.to(DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=4e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    cnt = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.to(DEVICE)\n",
    "        labels = labels.float()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        inputs = inputs.squeeze(1)  # Ensure the correct dimensions\n",
    "        outputs = model(inputs)\n",
    "        avg_loss += loss_fn(outputs, labels).item()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cnt += 1\n",
    "        print(\"                                                                                      \", end=\"\\r\")\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - batch {cnt}/{len(train_loader)} - loss: {avg_loss/cnt:.5f}\", end=\"\\r\")\n",
    "    losses.append(avg_loss/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "model.eval()\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for batch in train_loader:\n",
    "    inputs, label = batch\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    outputs = model(inputs)\n",
    "    preds = (outputs.argmax(dim=2).squeeze().tolist())\n",
    "    predictions += preds\n",
    "    label = label.argmax(dim=1).squeeze().tolist()\n",
    "    labels += label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels, predictions)\n",
    "print(cm)\n",
    "print(classification_report(labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
